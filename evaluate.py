import os
import torch
import pandas as pd
import numpy as np
from tqdm import tqdm

# åŸºç¡€é…ç½®ä¸å·¥å…·å¯¼å…¥
from config import Config
from utils.metrics import calculate_mae, calculate_rmse, calculate_pcc, calculate_prd
from utils.ptbxl_loader import get_ptbxl_evaluate_loader
from utils.ludb_loader import get_ludb_evaluate_loader

from models import *

# =============================================================
# 1. è‡ªåŠ¨åŒ–è¯„ä¼°é…ç½® (ä¿®æ”¹æ­¤å¤„å³å¯å¢åŠ æ–°å†…å®¹)
# =============================================================

# ã€æ•°æ®é›†æ¸…å•ã€‘ï¼š{ "å±•ç¤ºåç§°": åŠ è½½å™¨å‡½æ•° }
# æ¯ä¸ªåŠ è½½å™¨éœ€éµå¾ª (val_loader, demo_sig) çš„è¿”å›æ ¼å¼
DATASETS_TO_RUN = {
    "PTBXL": get_ptbxl_evaluate_loader,
    "LUDB": get_ludb_evaluate_loader,
}

# ã€æŒ‡æ ‡æ¸…å•ã€‘ï¼š{ "åˆ—å": metrics.py ä¸­çš„å‡½æ•°å }
# è¯„ä¼°æ—¶ä¼šè‡ªåŠ¨éå†è¿™äº›å‡½æ•°å¹¶è®°å½•ç»“æœ
METRICS_TO_CALC = {
    "MAE": calculate_mae,
    "RMSE": calculate_rmse,
    "PCC": calculate_pcc,
    "PRD": calculate_prd,
}

def get_eval_models(device):
    """
    é€‚é…å­—å…¸æ ¼å¼ä¿å­˜çš„æƒé‡åŠ è½½é€»è¾‘
    """
    # 1. è®¾ç½®æƒé‡å­˜æ”¾ç›®å½•å’Œæ•°æ®é›†åç§°
    # ç¡®ä¿è¿™ä¸ªè·¯å¾„æŒ‡å‘ä½ æˆªå›¾é‡Œçš„é‚£ä¸ªæ–‡ä»¶å¤¹
    checkpoint_dir = Config.CHECKPOINT_DIR  
    data_name = "PTBXL" 

    def load_dict_weights(models_to_load, model_file_prefix):
        """
        è¾…åŠ©å‡½æ•°ï¼šä»å­—å…¸ checkpoint ä¸­è§£åŒ…å¹¶åŠ è½½æƒé‡
        models_to_load: { "key_åœ¨å­—å…¸é‡Œçš„åç§°": model_å®ä¾‹ }
        """
        file_name = f"{model_file_prefix}_{data_name}_ep50.pth"
        path = os.path.join(checkpoint_dir, file_name)
        
        if os.path.exists(path):
            print(f" âœ… æ­£åœ¨åŠ è½½æƒé‡æ–‡ä»¶: {file_name}")
            # åŠ è½½æ•´ä¸ªå­—å…¸
            checkpoint = torch.load(path, map_location=device)
            
            for key, model_obj in models_to_load.items():
                if key in checkpoint:
                    model_obj.load_state_dict(checkpoint[key])
                    model_obj.eval() # å¼€å¯è¯„ä¼°æ¨¡å¼
                    print(f"   ğŸ‘‰ å­æ¨¡å— '{key}' åŠ è½½æˆåŠŸ")
                else:
                    print(f"   âš ï¸ è­¦å‘Šï¼šåœ¨ {file_name} ä¸­æ‰¾ä¸åˆ°é”® '{key}'ï¼Œè¯·æ£€æŸ¥ä¿å­˜æ—¶çš„ models_dict")
        else:
            print(f" âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°è·¯å¾„ {path}")
        
        # è¿”å›åŠ è½½åçš„æ¨¡å‹ï¼ˆå¦‚æœæ˜¯å¤šä¸ªåˆ™è¿”å›å…ƒç»„ï¼‰
        res = list(models_to_load.values())
        return res[0] if len(res) == 1 else tuple(res)

    # --- 2. æŒ‰ç…§ä½ çš„æ–‡ä»¶åæˆªå›¾ é€ä¸ªåŠ è½½ ---

    # ECGRecover: å‡è®¾ä½ ä¿å­˜æ—¶ç”¨çš„ key æ˜¯ "model"
    m_ecgrecover = load_dict_weights({"model": ECGRecover().to(device)}, "ECGRecover")

    # MaeFE: å‡è®¾ä½ ä¿å­˜æ—¶ç”¨çš„ key æ˜¯ "model"
    m_maefe = load_dict_weights({"model": MaeFE().to(device)}, "MaeFE")

    # EKGAN: å‡è®¾ä½ ä¿å­˜æ—¶ç”¨çš„ key æ˜¯ "generator"
    m_ekgan = load_dict_weights({"generator": EKGAN_Generator().to(device)}, "EKGAN")

    # DeScoD: å‡è®¾ä½ ä¿å­˜æ—¶ç”¨çš„ key æ˜¯ "model"
    m_descod = load_dict_weights({"model": DeScoD_ScoreNet().to(device)}, "DeScoD")

    # Unet_Flow: è¿™æ˜¯ç»„åˆæ¨¡å‹ï¼Œå‡è®¾ä¿å­˜æ—¶é”®ä¸º "unet" å’Œ "flow"
    # æ ¹æ®ä½ çš„æˆªå›¾ï¼Œæ–‡ä»¶åä¸º Unet_Flow_PTBXL_best.pth
    m_unet_flow = load_dict_weights({
        "unet": AdvancedUNet1D().to(device),
        "flow": FlowNetwork().to(device)
    }, "Unet_Flow")
    
    m_unet_moe_flow = load_dict_weights({
        "unet": AdvancedUNet1D().to(device),
        "moe_flow": MoEFlowNetwork().to(device)
    }, "Unet_MoE_Flow")

    return {
        "ECGRecover": m_ecgrecover,
        "MaeFE": m_maefe,
        "EKGAN": m_ekgan,
        "DeScoD": m_descod,
        "Unet_Flow": m_unet_flow, # æ­¤æ—¶å·²æ˜¯ (unet, flow) å…ƒç»„
        "Unet_MoE_Flow": m_unet_moe_flow,
    }

# =============================================================
# 2. è¯„ä¼°æ ¸å¿ƒé€»è¾‘ (é€šç”¨æ¡†æ¶ï¼Œæ— éœ€æ”¹åŠ¨)
# =============================================================

def run_evaluation():
    device = Config.DEVICE
    models_dict = get_eval_models(device)
    all_results = []

    # ç¬¬ä¸€å±‚å¾ªç¯ï¼šéå†æ•°æ®é›†
    for ds_name, loader_func in DATASETS_TO_RUN.items():
        print(f"\nğŸ“Š æ­£åœ¨è¯„ä¼°æ•°æ®é›†: {ds_name}")
        
        # è·å–è¯„ä¼°åŠ è½½å™¨
        # æ³¨æ„ï¼šæ­¤å¤„çš„ val_loader æ ·æœ¬æ•°å— Config.EVALUATE_SAMPLE_LIMIT é™åˆ¶
        val_loader, _ = loader_func() 

        # ç¬¬äºŒå±‚å¾ªç¯ï¼šéå†æ¨¡å‹
        for model_name, model_obj in models_dict.items():
            print(f"  ğŸ” æ¨¡å‹æ¨ç†ä¸­: {model_name}")
            
            # åˆå§‹åŒ–è¯¥æ¨¡å‹åœ¨æ­¤æ•°æ®é›†ä¸‹çš„å„é¡¹æŒ‡æ ‡å®¹å™¨
            perf_accumulator = {m_name: [] for m_name in METRICS_TO_CALC.keys()}

            for batch_x, batch_y in tqdm(val_loader, desc=f"    {model_name}"):
                # batch_x/y å½¢çŠ¶ä¸º (B, 12, 512)
                # ä¸ºäº†é€‚é… predictï¼Œéœ€è½¬ä¸º (B, 512, 12)
                input_np = batch_x.permute(0, 2, 1).numpy()
                
                with torch.no_grad():
                    # --- åˆ†æ”¯å¤„ç†ï¼šç»„åˆæ¨¡å‹ä¸æ™®é€šæ¨¡å‹ ---
                    if model_name in ["Unet_Flow", "Unet_MoE_Flow"]:
                        unet_m, flow_m = model_obj
                        # ç¬¬ä¸€é˜¶æ®µï¼šUNet é‡å»º
                        mid_res = unet_m.predict(input_np, device=device)
                        # ç¬¬äºŒé˜¶æ®µï¼šFlow ç»†åŒ–
                        pred_np = flow_m.predict(mid_res, steps=Config.SAMPLE_STEPS, device=device)
                    elif model_name == "DeScoD":
                        # æ‰©æ•£æ¨¡å‹æ¨ç†
                        pred_np = model_obj.predict(input_np, steps=Config.DIFF_STEPS, device=device)
                    else:
                        # é€šç”¨å•ä½“æ¨¡å‹é¢„æµ‹
                        pred_np = model_obj.predict(input_np, device=device)

                # å°†ç»“æœè½¬å› (B, 12, 512) ä»¥åŒ¹é…è®¡ç®—æŒ‡æ ‡æ—¶çš„ batch_y
                pred_torch = torch.from_numpy(pred_np).permute(0, 2, 1)
                
                # --- ç¬¬ä¸‰å±‚å¾ªç¯ï¼šåŠ¨æ€è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ ---
                for m_name, m_func in METRICS_TO_CALC.items():
                    # ä¼ å…¥å½¢çŠ¶å‡ä¸º (B, 12, 512)
                    val = m_func(batch_y, pred_torch)
                    perf_accumulator[m_name].append(val)

            # æ±‡æ€»å½“å‰æ¨¡å‹åœ¨å½“å‰æ•°æ®é›†ä¸Šçš„å¹³å‡è¡¨ç°
            res_entry = {"Dataset": ds_name, "Model": model_name}
            for m_name in METRICS_TO_CALC.keys():
                res_entry[m_name] = np.mean(perf_accumulator[m_name])
            
            all_results.append(res_entry)

    # 3. ç»“æœæŒä¹…åŒ–
    df = pd.DataFrame(all_results)
    df.to_csv(Config.METRICS_CSV, index=False)
    
    print(f"\nâœ… è¯„ä¼°å®Œæˆï¼ç»“æœå·²å­˜è‡³: {Config.METRICS_CSV}")
    print("-" * 60)
    print(df.to_string(index=False))

if __name__ == "__main__":
    run_evaluation()